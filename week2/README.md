# Week 2: Markov Descion Processes and Dynamic Programming

## Summary
This weeks theme is understanding the basic mathematic framework of describing staes , value functions ,policies.
MDP's provide a formal framework to model our problem.
Dynamic Programming is a general technique of solving sequntial problems optimally.In the context of this project we use Dynamic Programming to compute the optimal Policy and the "true" Value function for a given **complete information MDP**
Note that there is still no "learning" involved as such in these step. Feedback based learning will be the theme for the next  section after which we start with our main project!

## This weeks assignment
 ### 1. Understanding the mathematical formalisms :
 Go through the Exercies for chapter 3 from Sutton and Barto especially questions
> 3.1 ,3.2 ,3.5 ,3.8 , 3.12,3.13

### 2. Dynamic Programming : Gamblers Porblem
This is exercise 4.3 from the reference book(Problem Description Attached)
Task: Calculate and Plot the optimal policy and Value Function evolution over sweeps for P_h= 0.2 , 0.4 ,0.5,0.7,0.9

A template has for the python code has been attached. It is not manadatory to follow it.

* Bonus: Try to come up with an intuitive explanation for the nature of the Plots for different Values of P_h

    
